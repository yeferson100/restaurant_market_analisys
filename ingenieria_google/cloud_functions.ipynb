{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud Functions\n",
    "\n",
    "El presente archivo contiene todas las funciones implementadas para la automatización del proceso de ingeniería de las bases de datos de Google Maps. El procedimiento se basa sobre la máxima de que en un bucket llamado <strong>data-cruda</strong> ya se encuentran los datos que nos fueron brindados por Henry, y algunos archivos adicionales sobre información demográfica de los estados de Estados Unidos. El proceso consistió, primero, en eliminar tanto columnas como registros redundantes. Luego, una vez obtenidos únicamente datos de los estados de <strong> Maryland, Florida, Carolina del Norte, Carolina del Sur, Virginia</strong> y <strong>Georgia</strong>, y de <strong>restaurantes de tipo seafood</strong>, se procedió con el cálculo de los KPI. Con cada función, se trabajó un poco cada dataset y se almacenó en una carpeta dentro del bucket de data-cruda, llamada <em>data-preprocesada</em>, para luego ser llamado por la función subsecuente y repetir el proceso hasta tener los datasets terminados. <br>\n",
    "\n",
    "Cabe destacar que en las primeras 8 celdas se encuentran los códigos <strong>tal cual lo están en Google Cloud Functions</strong>, por lo que <strong>NO</strong> podrán ser ejecutadas. Para fines de brindar una demostración, están las últimas 8 celdas (que estarán marcadas con un markdown, para que el lector no tenga que contar a mano), en donde se replicará el funcionamiento pero desde un entorno local. <br> \n",
    "\n",
    "<strong> Las alteraciones importantes en el entorno local serán notificadas y justificadas </strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements.txt\n",
    "# functions-framework==3.*\n",
    "# pandas==2.1.0\n",
    "# numpy==1.24.3\n",
    "# flask==2.3.3\n",
    "# fsspec==2023.9.0\n",
    "# gcsfs==2023.9.0\n",
    "\n",
    "import functions_framework\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gcsfs\n",
    "import ast\n",
    "\n",
    "@functions_framework.http\n",
    "def metadata_1(request):\n",
    "\n",
    "\n",
    "  path_metadata = 'gs://data-cruda/google-maps/metadata/meta_states.csv' \n",
    "  df_metadata = pd.read_csv(path_metadata)\n",
    "\n",
    "  df_metadata.drop(columns=['description', 'address', 'longitude', 'latitude', 'price', 'hours', 'MISC', 'state', 'relative_results', 'url', 'num_of_reviews'], inplace=True)\n",
    "\n",
    "  def es_restaurant(categorias):\n",
    "      restaurant = False\n",
    "      for categoria in categorias:\n",
    "          categoria_lower = categoria.lower()\n",
    "          if 'seafood restaurant' in categoria_lower:\n",
    "              restaurant = True \n",
    "      \n",
    "      if restaurant:\n",
    "          return categorias\n",
    "      else:\n",
    "          return None\n",
    "\n",
    "  # Función para convertir las cadenas en listas, manejando los valores nulos\n",
    "  def parse_list(str_value):\n",
    "      try:\n",
    "          array = ast.literal_eval(str_value)\n",
    "          return es_restaurant(array)\n",
    "      except (ValueError, SyntaxError):\n",
    "          return None\n",
    "\n",
    "\n",
    "  df_metadata['category'] = df_metadata['category'].apply(parse_list)\n",
    "\n",
    "  df_metadata.dropna(subset=['category'], inplace=True)\n",
    "  df_metadata.rename(columns={'name': 'nombre_restaurant', 'estado': 'id_estado', 'avg_rating': 'valoracion_promedio'}, inplace=True)\n",
    "  df_metadata.drop(columns=['category'], inplace=True)\n",
    "  df_metadata = df_metadata[['gmap_id', 'nombre_restaurant', 'id_estado', 'valoracion_promedio']]\n",
    "\n",
    "  df_metadata.to_csv('gs://data-cruda/data-preprocesada/metadata_1.csv', index=False)\n",
    "  \n",
    "  return '', 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements.txt ------------------------------------\n",
    "# functions-framework==3.*\n",
    "# pandas==2.1.0\n",
    "# gcsfs==2023.9.0\n",
    "\n",
    "import functions_framework\n",
    "import pandas as pd\n",
    "import gcsfs\n",
    "\n",
    "@functions_framework.http\n",
    "def estados_1(request):\n",
    "\n",
    "  path_poblacion = 'gs://data-cruda/estados/estados_poblacion.csv'\n",
    "  path_superficie = 'gs://data-cruda/estados/superficie_estado.csv'\n",
    "\n",
    "  df_poblacion = pd.read_csv(path_poblacion)\n",
    "  df_superficie = pd.read_csv(path_superficie)\n",
    "\n",
    "  estados_proyecto = ['Florida', 'Georgia', 'Maryland', 'Carolina del Sur', 'Carolina del Norte', 'Virginia']\n",
    "\n",
    "  mask_poblacion = df_poblacion['Estado'].isin(estados_proyecto)\n",
    "  mask_superficie = df_superficie['Estado'].isin(estados_proyecto)\n",
    "\n",
    "  df_poblacion = df_poblacion[mask_poblacion]\n",
    "  df_superficie = df_superficie[mask_superficie]\n",
    "\n",
    "\n",
    "  df_estados = pd.merge(df_superficie, df_poblacion, on='Estado')\n",
    "\n",
    "  df_estados.drop(columns=['Unnamed: 0_x', 'Descripcion', 'Unnamed: 0_y', 'Densudad', 'Porc'], inplace=True)\n",
    "  df_estados.rename(columns={ 'siglas'    : 'id_estado',\n",
    "                              'Estado'    : 'estado',\n",
    "                              'Poblacion' : 'poblacion',\n",
    "                              'superficie': 'superficie_km2'}, inplace=True)\n",
    "\n",
    "  df_estados = df_estados[['id_estado', 'estado', 'superficie_km2', 'poblacion']]\n",
    "\n",
    "\n",
    "  df_estados.to_csv('gs://data-cruda/data-preprocesada/estados_1.csv', index=False)\n",
    "\n",
    "  return '', 200\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements.txt -------------------------------- \n",
    "# functions-framework==3.*\n",
    "# pandas==2.1.0\n",
    "# numpy==1.24.3\n",
    "# gcsfs==2023.9.0\n",
    "# pyarrow==13.0.0\n",
    "# fsspec==2023.9.0\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gcsfs\n",
    "import functions_framework\n",
    "\n",
    "@functions_framework.http\n",
    "def metadata_2(request):\n",
    "\n",
    "    # Crea un sistema de archivos GCS\n",
    "    credenciales = {\n",
    "        \"type\": \"service_account\",\n",
    "        \"project_id\": \"proyecto-final-henry-397316\",\n",
    "        \"private_key_id\": \"6c67fe28b78e691a29afa013e3a825468b8475a2\",\n",
    "        \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQC1j/xVTRN/TDiZ\\nt4ZcwYZmZSVJPcIHWk+E40817BJR72Fy1u8mlXBKyFy9PwJN52JHfu5EvFaWBPmk\\nqBdRacLPwHzsMwq53iWClYf3Xmh8qEtr+22DBm3zEZcygfykqQ04+7CLSslTlOeX\\nDt2KuJtwokMrbUq6/FjdrVJybgkCCqFBZHVRrwqnWPtGzp26/a/LD67VbxzvNWRp\\nnvE+WzDxoCkq1fWCuaJlKPObP5e69J4QYkzBiQKaNBS99z7cpgjYXesa9O0ayoo2\\nu5taDUbP8BR+tR2xjGcKyhr+cMuMcOAq2T9UYHya9pwwK1Um6tgGSzslj8AA3koL\\nAVkhLDBhAgMBAAECggEADFWsL+Nc8rtWkQ2IdvQS0bwHYh1sTsbnkMCcmK42ub2d\\n4jO7QDogzIPQ1m6Eao8l/HN2ySapFJIL9RASXXk7lJT1fQUkB708JnigKcG5LtbZ\\ndjbjmWYuFrhYNu82dGf5D6j8X8ovOUVsImAOfvvMW5o6c/soe4w56/14FMa9nUIb\\n9ZRQVkkVLVoSO4HZzVYPo+DuBio6S0gZIuNhvkWYv/CvcfQwy8gbkpO82H5/fxOI\\noXiKhVrSY4KwKawUVrX7uQfcDs22Tz/5ksjOChTU8aBKo/EhwlmKBSymzbi3W3W2\\nvbZKx68hwwpQvT+TFW3Utg+Bd5HDcnV0ljbpuQ2vUQKBgQD8Vl0nzW3kxMYgbdsz\\nI9i+/xj8zWYzF7E77T/43D9PII59VfshXPYJY+O1Q13/uha/iUGoeUtD4UR3JoPI\\nN0W+3cyxLSvtjrGGQtr2WKqQBnu5fqg6fPvh1pbdSyd/WewkYrKU0L31jDtVW3W6\\nvNIeQMIbxpL2vktqK85izDALjQKBgQC4MqLW6+FFtsPd9RnTjT5MbsjCmsFNV202\\nK85E5QMeT92EgSO7NtPKrqDLVYXxTZEz+DJouGZkQlA2NXECdGhfCphLHvWIkSkM\\nYV7ET1w3HXvaa99AV+2C9XNQbFehF66ZgfuDqocYNfW594QUD4rQDHnCaWaGIMVC\\nXZu6IjDZJQKBgQDqHx9TfLDHnyLMl+DXNB04KOuAMvrt0L+qgFfoiEFdIzHRbGMS\\n83N8BugRGC4wxPGySKFYtSF2G54whtWigFX/3z657NVjFg/0KDeMdXvbIYjN9IwV\\nqDzzruxO6hn9eOs2XzSeCocVOkUazz8OQX8afq8aokVdFfZWzcoxtI2nSQKBgHOm\\nd09x8pMO2ZO2nGyTNhZPSIXHHK8uwUdN4cin8XlKs87KNmEJX5jWY+bG375N8Wkr\\n4JqXjNJOQIaIr1fXNuDViiFAYvFIEvnO+O1Q1plUTbsqF5YSnvGmoqxQGgTvFZUU\\nY5Kbsw6kcpA8tBTUXVebPaeu/cwhLzkoBOqtJPZxAoGAFw5ZJEMCMShgAaxxFakT\\nBvqv91qCRZmnublBheRsQkfe9k+3tfOk7Cqbu6dqdkAx2g8e3LhB7CLw/sxSR/ku\\nQ1huRsHfkwnKqxDyjOiU+GhxWHc/s9SkfYg9010k8YIEwP+nqzDRpFGaM81lTM9T\\n35jeN70j+ClR3fbzrXw0zNo=\\n-----END PRIVATE KEY-----\\n\",\n",
    "        \"client_email\": \"proyecto-final@proyecto-final-henry-397316.iam.gserviceaccount.com\",\n",
    "        \"client_id\": \"117580722272189124656\",\n",
    "        \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
    "        \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
    "        \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
    "        \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/proyecto-final%40proyecto-final-henry-397316.iam.gserviceaccount.com\",\n",
    "        \"universe_domain\": \"googleapis.com\"\n",
    "    }\n",
    "\n",
    "    fs = gcsfs.GCSFileSystem(project='proyecto-final-henry-397316', token=credenciales)\n",
    "\n",
    "\n",
    "    # files = os.listdir(path_carpeta_reviews) \n",
    "    path_carpeta_reviews = 'gs://data-cruda/google-maps/reviews/'\n",
    "\n",
    "    files = fs.ls(path_carpeta_reviews)\n",
    "\n",
    "    array_restaurantes = []\n",
    "    array_reviews = []\n",
    "\n",
    "    df_metadata = pd.read_csv('gs://data-cruda/data-preprocesada/metadata_1.csv')\n",
    "\n",
    "    for file in files:\n",
    "        if file.endswith('.parquet'):\n",
    "            with fs.open(file, 'rb') as f:\n",
    "                path_archivo = f'gs://{file}'\n",
    "\n",
    "                reviews = pd.read_parquet(path_archivo)\n",
    "                reviews.drop(columns=['name', 'user_id', 'pics', 'resp', 'text'], inplace=True)\n",
    "\n",
    "                restaurantes = [restaurante for restaurante in df_metadata['gmap_id']]\n",
    "\n",
    "                reviews = reviews[reviews['gmap_id'].isin(restaurantes)]\n",
    "\n",
    "                reviews.rename(columns={'time': 'fecha',\n",
    "                        'rating': 'valoracion',\n",
    "                        'state': 'id_estado'}, inplace=True)\n",
    "\n",
    "                reviews.drop_duplicates(inplace=True)\n",
    "                cant_reviews = reviews.value_counts(subset='gmap_id')\n",
    "                cant_reviews = pd.DataFrame(cant_reviews).reset_index()\n",
    "\n",
    "                estado = reviews['id_estado'].reset_index(drop=True)[0]\n",
    "\n",
    "                df_restaurante = pd.merge(cant_reviews, df_metadata, on='gmap_id', how='right')\n",
    "                df_restaurante = df_restaurante[df_restaurante['id_estado'] == estado]\n",
    "                array_restaurantes.append(df_restaurante)\n",
    "\n",
    "            reviews.drop(columns=['id_estado'], inplace=True)\n",
    "            array_reviews.append(reviews)\n",
    "\n",
    "\n",
    "    # Final dataframe de Reviews\n",
    "\n",
    "    reviews_final = pd.concat(array_reviews, ignore_index=True)\n",
    "    reviews_final.to_csv('gs://data-procesada/google-maps/reviews_google.csv')\n",
    "\n",
    "    restaurantes_final = pd.concat(array_restaurantes, ignore_index=True)\n",
    "    restaurantes_final.fillna(0, inplace=True)\n",
    "    restaurantes_final.rename(columns={'count': 'cant_reviews', 'avg_rating': 'valoracion_promedio' }, inplace=True)\n",
    "    restaurantes_final['cant_reviews'] = restaurantes_final['cant_reviews'].apply(lambda x: int(x))\n",
    "    restaurantes_final = restaurantes_final[['gmap_id', 'nombre_restaurant', 'id_estado', 'cant_reviews', 'valoracion_promedio']]\n",
    "\n",
    "    restaurantes_final.to_csv('gs://data-cruda/data-preprocesada/metadata_2.csv', index=False)\n",
    "\n",
    "    return '', 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements.txt ---------------------------------\n",
    "# functions-framework==3.*\n",
    "# pandas==2.1.0\n",
    "# numpy==1.24.3\n",
    "# gcsfs==2023.9.0\n",
    "\n",
    "import functions_framework\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import gcsfs\n",
    "\n",
    "@functions_framework.http\n",
    "def estados_2(request):\n",
    "\n",
    "    df_restaurantes = pd.read_csv('gs://data-cruda/data-preprocesada/metadata_2.csv')\n",
    "    df_estados = pd.read_csv('gs://data-cruda/data-preprocesada/estados_1.csv')\n",
    "\n",
    "## Cantidad de Restaurantes\n",
    "    def calcular_cant_rest(estado):\n",
    "        return  df_restaurantes[df_restaurantes['id_estado'] == estado]['gmap_id'].count()\n",
    "\n",
    "    df_estados['cant_rest'] = df_estados['id_estado'].apply(calcular_cant_rest)\n",
    "\n",
    "    # Calculo de columna de CRE (Concentracion de Restaurantes por Estado)\n",
    "    df_estados['CRE'] = df_estados['cant_rest'] / (df_estados['superficie_km2'] / 1000)\n",
    "\n",
    "    # Calculo de columna de DCP (Densidad de consumo segun poblacion)\n",
    "    df_estados['DCP'] = (df_estados['poblacion'] / 1000) / df_estados['cant_rest']\n",
    "\n",
    "    df_estados.to_csv('gs://data-cruda/data-preprocesada/estados_2.csv', index=False)\n",
    "\n",
    "    return '', 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements.txt ---------------------------------------\n",
    "# functions-framework==3.*\n",
    "# pandas==2.1.0\n",
    "# numpy==1.24.3\n",
    "# gcsfs==2023.9.0\n",
    "\n",
    "# Calculo de columna de Segmentacion de comercio en el dataframe de restaurantes\n",
    "\n",
    "import functions_framework\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import gcsfs\n",
    "\n",
    "@functions_framework.http\n",
    "def metadata_3(request):\n",
    "\n",
    "    def Gen_Estadisticos(data):\n",
    "        q1 = np.percentile(data, 25)\n",
    "        Mediana = np.percentile(data, 50)\n",
    "        q3 = np.percentile(data, 75)\n",
    "        mean = np.mean(data)\n",
    "        std = np.std(data)\n",
    "        minimo = min(data)\n",
    "        maximo = max(data)\n",
    "        return q1,Mediana,q3,mean,std,minimo,maximo\n",
    "\n",
    "    data_umbrales = {'NC': {'mediana': 0,\n",
    "                        'reduccion': 0,\n",
    "                        'porc_reduccion': 94},\n",
    "                    'SC': {'mediana': 0,\n",
    "                        'reduccion': 0,\n",
    "                        'porc_reduccion': 91},\n",
    "                    'FL': {'mediana': 0,\n",
    "                        'reduccion': 0,\n",
    "                        'porc_reduccion': 91},\n",
    "                    'GA': {'mediana': 0,\n",
    "                        'reduccion': 0,\n",
    "                        'porc_reduccion': 93},\n",
    "                    'MD': {'mediana': 0,\n",
    "                        'reduccion': 0,\n",
    "                        'porc_reduccion': 86},\n",
    "                    'VA': {'mediana': 0,\n",
    "                        'reduccion': 0,\n",
    "                        'porc_reduccion': 94}}\n",
    "\n",
    "    df_estados = pd.read_csv('gs://data-cruda/data-preprocesada/estados_2.csv')\n",
    "    df_restaurantes = pd.read_csv('gs://data-cruda/data-preprocesada/metadata_2.csv')\n",
    "\n",
    "    for estado in df_estados['id_estado']:\n",
    "        \n",
    "        mask = df_restaurantes['id_estado'] == estado\n",
    "        df_temp = df_restaurantes[mask]\n",
    "\n",
    "        var = data_umbrales[estado]['porc_reduccion']\n",
    "        reduccion = np.percentile(df_temp['cant_reviews'], var)\n",
    "        \n",
    "        df_reducido = df_temp[df_temp['cant_reviews'] <= reduccion]\n",
    "        df_reducido = df_reducido[df_reducido['cant_reviews'] > 0]\n",
    "        \n",
    "        q1,mediana,q3,mean,std,minimo,maximo = Gen_Estadisticos(df_reducido.cant_reviews)\n",
    "        \n",
    "        data_umbrales[estado]['mediana'] = mediana\n",
    "        data_umbrales[estado]['reduccion'] = reduccion\n",
    "\n",
    "    def Seg_comercios(valor,Partidor1,Partidor2):\n",
    "        if valor <= Partidor1:\n",
    "            var = 1\n",
    "        elif valor <= Partidor2:\n",
    "            var = 2\n",
    "        else: \n",
    "            var = 3\n",
    "        return var\n",
    "\n",
    "    def apply_transform(row, umbrales):\n",
    "        estado = row['id_estado']\n",
    "        cant_reviews = row['cant_reviews']\n",
    "        for estado_umbral in umbrales:\n",
    "            if estado_umbral == estado:\n",
    "                reduccion = umbrales[estado_umbral]['reduccion']\n",
    "                mediana = umbrales[estado_umbral]['mediana']\n",
    "                return Seg_comercios(cant_reviews, mediana, reduccion)\n",
    "        return cant_reviews\n",
    "\n",
    "    df_restaurantes['SEG_DCP'] = df_restaurantes.apply(lambda x: apply_transform(x, data_umbrales), axis=1)\n",
    "\n",
    "    df_restaurantes.to_csv('gs://data-cruda/data-preprocesada/metadata_3.csv', index=False)\n",
    "\n",
    "    return '', 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requirements.txt -------------------------------\n",
    "#functions-framework==3.*\n",
    "#pandas==2.1.0\n",
    "#numpy==1.24.3\n",
    "#gcsfs==2023.9.0\n",
    "\n",
    "\n",
    "import functions_framework\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gcsfs\n",
    "\n",
    "@functions_framework.http\n",
    "def estados_3(request):\n",
    "\n",
    "    df_estados = pd.read_csv('gs://data-cruda/data-preprocesada/estados_2.csv')\n",
    "    df_restaurantes = pd.read_csv('gs://data-cruda/data-preprocesada/metadata_3.csv')\n",
    "\n",
    "    # Calculo de las columnas de promedio y maximo de reviews por estado\n",
    "    def asig_Rev_Prom(estado, df):\n",
    "        return df[df[\"id_estado\"] == estado][\"cant_reviews\"].mean()\n",
    "\n",
    "    def asig_Rev_Max(estado, df):\n",
    "        return df[df[\"id_estado\"] == estado][\"cant_reviews\"].max()\n",
    "\n",
    "    df_estados[\"Rev_Prom\"] = df_estados[\"id_estado\"].apply(lambda x: asig_Rev_Prom(x, df_restaurantes) if True else x)\n",
    "    df_estados[\"Rev_Max\"] = df_estados[\"id_estado\"].apply(lambda x: asig_Rev_Max(x, df_restaurantes) if True else x)\n",
    "\n",
    "    df_estados[\"Ind_DCP_Prom\"] = df_estados[\"Rev_Prom\"] / df_estados[\"DCP\"] \n",
    "    df_estados[\"Ind_DCP_Max\"] = df_estados[\"Rev_Max\"] / df_estados[\"DCP\"] \n",
    "\n",
    "    # Calculo de maximo y promedio de reseñas por segmento y estado\n",
    "\n",
    "    def calcular_estadisticos_segmento(data, segmento):\n",
    "        # Filtrar el DataFrame por el segmento dado\n",
    "        data_segmento = data[data[\"SEG_DCP\"] == segmento]\n",
    "\n",
    "        # Calcular el valor máximo y el promedio de reseñas por estado\n",
    "        resultados = data_segmento.groupby([\"id_estado\"])[\"cant_reviews\"].agg([\"mean\", \"max\"]).reset_index()\n",
    "        resultados.columns = [\"id_estado\", f\"Ind_DCP_prom_seg_{segmento}\", f\"Ind_DCP_max_seg_{segmento}\"]\n",
    "\n",
    "        return resultados\n",
    "\n",
    "    estadisticos_seg_1 = calcular_estadisticos_segmento(df_restaurantes, 1)\n",
    "    estadisticos_seg_2 = calcular_estadisticos_segmento(df_restaurantes, 2)\n",
    "    estadisticos_seg_3 = calcular_estadisticos_segmento(df_restaurantes, 3)\n",
    "\n",
    "\n",
    "    dataframe_estadisticas_segmentos = pd.merge(estadisticos_seg_1, estadisticos_seg_2, on='id_estado')\n",
    "    dataframe_estadisticas_segmentos = pd.merge(dataframe_estadisticas_segmentos, estadisticos_seg_3, on='id_estado')\n",
    "    df_estados = pd.merge(df_estados, dataframe_estadisticas_segmentos, on='id_estado')\n",
    "\n",
    "    \n",
    "    # Reduccion de las ultimas columnas agregadas por DCP para volverlas indices.\n",
    "    columnas = [\"Ind_DCP_prom_seg_1\", \"Ind_DCP_max_seg_1\", \"Ind_DCP_prom_seg_2\", \"Ind_DCP_max_seg_2\", \"Ind_DCP_prom_seg_3\", \"Ind_DCP_max_seg_3\"]\n",
    "\n",
    "    for columna in columnas:\n",
    "        df_estados[columna] = df_estados[columna] / df_estados[\"DCP\"]\n",
    "\n",
    "    df_estados.to_csv('gs://data-cruda/data-preprocesada/estados_3.csv', index=False)\n",
    "\n",
    "    return '', 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requirements.txt -------------------------------\n",
    "#functions-framework==3.*\n",
    "#pandas==2.1.0\n",
    "#numpy==1.24.3\n",
    "#gcsfs==2023.9.0\n",
    "\n",
    "\n",
    "import functions_framework\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gcsfs\n",
    "\n",
    "@functions_framework.http\n",
    "def estados_4(request):\n",
    "\n",
    "    df_estados = pd.read_csv('gs://data-cruda/data-preprocesada/estados_3.csv')\n",
    "    df_restaurantes = pd.read_csv('gs://data-cruda/data-preprocesada/metadata_3.csv')\n",
    "\n",
    "    # Calculo de las columnas de PEE_prom y PEE_max\n",
    "\n",
    "    promedio_valoracion_por_estado = df_restaurantes.groupby(\"id_estado\")[\"valoracion_promedio\"].mean().reset_index()\n",
    "    maximo_valoracion_por_estado = df_restaurantes.groupby('id_estado')['valoracion_promedio'].max().reset_index()\n",
    "\n",
    "    # Renombrar la columna resultante\n",
    "    promedio_valoracion_por_estado.columns = [\"id_estado\", \"PEE_prom\"]\n",
    "    maximo_valoracion_por_estado.columns = ['id_estado', 'PEE_max']\n",
    "\n",
    "    dataframe_pee_max_prom = pd.merge(promedio_valoracion_por_estado, maximo_valoracion_por_estado, on='id_estado')\n",
    "    dataframe_pee_max_prom\n",
    "\n",
    "    df_estados = pd.merge(df_estados, dataframe_pee_max_prom, on='id_estado')\n",
    "\n",
    "    #Calculo de las columnas de PEE_prom y PEE_max por estado\n",
    "\n",
    "    # Calcular el promedio de \"valoracion_promedio\" por estado y segmento\n",
    "    promedio_valoracion_por_estado_segmento = df_restaurantes.groupby([\"id_estado\", \"SEG_DCP\"])[\"valoracion_promedio\"].mean().reset_index()\n",
    "\n",
    "    # Calcular el máximo de \"valoracion_promedio\" por estado y segmento\n",
    "    maximo_valoracion_por_estado_segmento = df_restaurantes.groupby([\"id_estado\", \"SEG_DCP\"])[\"valoracion_promedio\"].max().reset_index()\n",
    "\n",
    "    # Renombrar las columnas resultantes\n",
    "    promedio_valoracion_por_estado_segmento.columns = [\"id_estado\", \"SEG_DCP\", \"PEE_prom\"]\n",
    "    maximo_valoracion_por_estado_segmento.columns = [\"id_estado\", \"SEG_DCP\", \"PEE_max\"]\n",
    "\n",
    "    # Pivotear los DataFrames para obtener el formato deseado\n",
    "    promedio_valoracion_por_estado_segmento = promedio_valoracion_por_estado_segmento.pivot(index=\"id_estado\", columns=\"SEG_DCP\", values=\"PEE_prom\").reset_index()\n",
    "    maximo_valoracion_por_estado_segmento = maximo_valoracion_por_estado_segmento.pivot(index=\"id_estado\", columns=\"SEG_DCP\", values=\"PEE_max\").reset_index()\n",
    "\n",
    "    # Renombrar las columnas de los DataFrames pivotados\n",
    "    promedio_valoracion_por_estado_segmento.columns = [\"id_estado\", \"PEE_prom_seg_1\", \"PEE_prom_seg_2\", \"PEE_prom_seg_3\"]\n",
    "    maximo_valoracion_por_estado_segmento.columns = [\"id_estado\", \"PEE_max_seg_1\", \"PEE_max_seg_2\", \"PEE_max_seg_3\"]\n",
    "\n",
    "    # Combinar los resultados en un solo DataFrame\n",
    "    resultados_pee = pd.merge(promedio_valoracion_por_estado_segmento, maximo_valoracion_por_estado_segmento, on=\"id_estado\")\n",
    "\n",
    "    df_estados = pd.merge(df_estados, resultados_pee, on='id_estado')\n",
    "\n",
    "    df_estados.to_csv('gs://data-cruda/data-preprocesada/estados_4.csv', index=False)\n",
    "\n",
    "    return '', 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requirements.txt -------------------------------\n",
    "#functions-framework==3.*\n",
    "#pandas==2.1.0\n",
    "#numpy==1.24.3\n",
    "#gcsfs==2023.9.0\n",
    "\n",
    "\n",
    "import functions_framework\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gcsfs\n",
    "\n",
    "@functions_framework.http\n",
    "def final_funct(request):\n",
    "\n",
    "    df_estados = pd.read_csv('gs://data-cruda/data-preprocesada/estados_4.csv')\n",
    "    df_restaurantes = pd.read_csv('gs://data-cruda/data-preprocesada/metadata_3.csv')\n",
    "    # Normalizacion\n",
    "\n",
    "    def normalizacion(valor,minimo,maximo,base,min_base):\n",
    "        var = min_base + (((valor - minimo) / (maximo - minimo)) * base)\n",
    "        return var\n",
    "\n",
    "    lista_indices = [\"Ind_DCP_prom_seg_1\",\"Ind_DCP_prom_seg_2\",\"Ind_DCP_prom_seg_3\",\"Ind_DCP_max_seg_1\",\"Ind_DCP_max_seg_2\",\"Ind_DCP_max_seg_3\"]\n",
    "    lista_ind_Nor = [\"Ind_DCP_prom_seg_1_nor\",\"Ind_DCP_prom_seg_2_nor\",\"Ind_DCP_prom_seg_3_nor\",\"Ind_DCP_max_seg_1_nor\",\"Ind_DCP_max_seg_2_nor\",\"Ind_DCP_max_seg_3_nor\"]\n",
    "    for i in range(0,len(lista_indices)):\n",
    "        minimo = df_estados[lista_indices[i]].min()\n",
    "        maximo = df_estados[lista_indices[i]].max()\n",
    "        df_estados[lista_ind_Nor[i]] = df_estados[lista_indices[i]].apply(lambda x:normalizacion(x,minimo,maximo,80,20) if True else x)\n",
    "\n",
    "\n",
    "    df_estados = df_estados[[\"id_estado\",\"estado\",\"superficie_km2\",\"poblacion\",\"cant_rest\",\n",
    "                            \"CRE\",\"DCP\",\"Rev_Prom\",\"Rev_Max\",\"PEE_prom\",\"PEE_max\",\n",
    "                            \"Ind_DCP_Prom\",\"Ind_DCP_Max\",\n",
    "                            \"Ind_DCP_prom_seg_1\",\"Ind_DCP_prom_seg_1_nor\",\n",
    "                            \"Ind_DCP_prom_seg_2\",\"Ind_DCP_prom_seg_2_nor\",\n",
    "                            \"Ind_DCP_prom_seg_3\",\"Ind_DCP_prom_seg_3_nor\",\n",
    "                            \"Ind_DCP_max_seg_1\",\"Ind_DCP_max_seg_1_nor\",\n",
    "                            \"Ind_DCP_max_seg_2\",\"Ind_DCP_max_seg_2_nor\",\n",
    "                            \"Ind_DCP_max_seg_3\",\"Ind_DCP_max_seg_3_nor\",\n",
    "                            \"PEE_prom_seg_1\",\"PEE_prom_seg_2\",\"PEE_prom_seg_3\",\n",
    "                            \"PEE_max_seg_1\",\"PEE_max_seg_2\",\"PEE_max_seg_3\"]]\n",
    "\n",
    "\n",
    "\n",
    "    def calcular_cumple(row):\n",
    "        estado = row[\"id_estado\"]\n",
    "        segmento = row[\"SEG_DCP\"]\n",
    "        cant_reviews = row[\"cant_reviews\"]\n",
    "        valoracion_promedio = row[\"valoracion_promedio\"]\n",
    "        rest_id = row['gmap_id']\n",
    "\n",
    "        # Obtener los valores de DCP_prom y PEE_prom correspondientes al estado y segmento\n",
    "        DCP_prom = df_estados[(df_estados[\"id_estado\"] == estado)][f\"Ind_DCP_prom_seg_{segmento}\"].values[0]\n",
    "        PEE_prom = df_estados[(df_estados[\"id_estado\"] == estado)][f\"PEE_prom_seg_{segmento}\"].values[0]\n",
    "\n",
    "        # Calcular las condiciones y asignar 1 o 0\n",
    "        DCP_cumple = 1 if cant_reviews > DCP_prom else 0\n",
    "        PEE_cumple = 1 if valoracion_promedio > PEE_prom else 0\n",
    "\n",
    "        return pd.Series({'gmap_id': rest_id, \"DCP_cumple\": DCP_cumple, \"PEE_cumple\": PEE_cumple})\n",
    "\n",
    "\n",
    "    df_restaurantes = pd.merge(df_restaurantes, df_restaurantes.apply(calcular_cumple, axis=1), on='gmap_id')\n",
    "\n",
    "    df_estados.to_csv('gs://data-procesada/google-maps/estados.csv', index=False)\n",
    "    df_estados.to_csv('gs://data-procesada/google-maps/restaurantes.csv', index=False)\n",
    "\n",
    "    return '', 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réplica en entorno local\n",
    "\n",
    "Para fines prácticos, las librerías se importarán una única vez en la próxima celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celda 1\n",
    "\n",
    "Esta celda comienza a procesar la tabla de <strong>restaurantes</strong>, que hasta que esté lista conservará el nombre de <strong>metadata</strong>. Se realiza una limpieza de columnas, de registros y se estandarizan los nombres de algunas columnas. Las únicas diferencias con la función implementada en Google Cloud Functions son las rutas, y la división del archivo princpal de meta_states en 2 archivos de menor tamaño en formato parquet para que puedan ser subidos a GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_parquet('data-cruda/google-maps/metadata/meta_states_1.parquet')\n",
    "df_2 = pd.read_parquet('data-cruda/google-maps/metadata/meta_states_2.parquet')\n",
    "\n",
    "df_metadata = pd.concat([df_1, df_2], axis=0, ignore_index=True)\n",
    "\n",
    "df_metadata.drop(columns=['description', 'address', 'longitude', 'latitude', 'price', 'hours', 'MISC', 'state', 'relative_results', 'url', 'num_of_reviews'], inplace=True)\n",
    "\n",
    "def es_restaurant(categorias):\n",
    "    restaurant = False\n",
    "    for categoria in categorias:\n",
    "        categoria_lower = categoria.lower()\n",
    "        if 'seafood restaurant' in categoria_lower:\n",
    "            restaurant = True \n",
    "    \n",
    "    if restaurant:\n",
    "        return categorias\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Función para convertir las cadenas en listas, manejando los valores nulos\n",
    "def parse_list(str_value):\n",
    "    try:\n",
    "        array = ast.literal_eval(str_value)\n",
    "        return es_restaurant(array)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return None\n",
    "\n",
    "\n",
    "df_metadata['category'] = df_metadata['category'].apply(parse_list)\n",
    "\n",
    "df_metadata.dropna(subset=['category'], inplace=True)\n",
    "df_metadata.rename(columns={'name': 'nombre_restaurant', 'estado': 'id_estado', 'avg_rating': 'valoracion_promedio'}, inplace=True)\n",
    "df_metadata.drop(columns=['category'], inplace=True)\n",
    "df_metadata = df_metadata[['gmap_id', 'nombre_restaurant', 'id_estado', 'valoracion_promedio']]\n",
    "\n",
    "df_metadata.to_csv('data-cruda/data-preprocesada/metadata_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celda 2\n",
    "Se realiza la poda inicial a la tabla de <strong>estados</strong>. Se deshechan los estados redundantes, se combinan los datos de un dataframe de <strong>superficie por estado en km²</strong> con los de otro de <strong>población por estado</strong>, y se estandarizan nombres de las columnas. Se guarda en un archivo llamado <em>estados_1.csv</em> en la carpeta de <em>data-preprocesada</em>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_poblacion = 'data-cruda/estados/estados_poblacion.csv'\n",
    "path_superficie = 'data-cruda/estados/superficie_estado.csv'\n",
    "\n",
    "df_poblacion = pd.read_csv(path_poblacion)\n",
    "df_superficie = pd.read_csv(path_superficie)\n",
    "\n",
    "estados_proyecto = ['Florida', 'Georgia', 'Maryland', 'Carolina del Sur', 'Carolina del Norte', 'Virginia']\n",
    "\n",
    "mask_poblacion = df_poblacion['Estado'].isin(estados_proyecto)\n",
    "mask_superficie = df_superficie['Estado'].isin(estados_proyecto)\n",
    "\n",
    "df_poblacion = df_poblacion[mask_poblacion]\n",
    "df_superficie = df_superficie[mask_superficie]\n",
    "\n",
    "\n",
    "df_estados = pd.merge(df_superficie, df_poblacion, on='Estado')\n",
    "\n",
    "df_estados.drop(columns=['Unnamed: 0_x', 'Descripcion', 'Unnamed: 0_y', 'Densudad', 'Porc'], inplace=True)\n",
    "df_estados.rename(columns={ 'siglas'    : 'id_estado',\n",
    "                            'Estado'    : 'estado',\n",
    "                            'Poblacion' : 'poblacion',\n",
    "                            'superficie': 'superficie_km2'}, inplace=True)\n",
    "\n",
    "df_estados = df_estados[['id_estado', 'estado', 'superficie_km2', 'poblacion']]\n",
    "\n",
    "\n",
    "df_estados.to_csv('data-cruda/data-preprocesada/estados_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celda 3\n",
    "En esta celda, principalmente se calcula una columna de <em>cantidad de reviews por restaurante</em>, además de normalizar algunos nombres de columnas. Para fines prácticos, la celda tiene algunas diferencias con respecto a la función original de Functions: <br>\n",
    "<ol>\n",
    "    <li>La búsqueda de archivos parquet se hace de forma local, en lugar de buscar en el bucket como lo hace la función de Cloud Functions. Por ello, se utiliza la libreria os y se itera sobre la carpeta en donde se encuentran los archivos. En la función original se usa la libreria gcsfs para poder entrar al bucket, sin haber mostrado previamente las credenciales de la cuenta de servicio que brinda la plataforma. Esto se puede ver bien en la celda 3 original.</li><br>\n",
    "    <li>Debido a las limitaciones que supone un entorno local, los archivos parquet que se encuentran en este directorio, si bien tienen distintos nombres, <strong>todos contienen información sobre Virgina</strong>, ya que es el estado con menor registros y hacerlo de este modo permitía correr pruebas desde una computadora personal. Por ello, al final de la celda, se sobreescribirá el resultado final del dataframe por uno que contenga información sobre todos los estados, pues sin llevar a cabo esta corrección, <strong>no se podrían ejecutar las demás celdas</strong>.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_carpeta_reviews = 'data-cruda/google-maps/reviews/'\n",
    "\n",
    "# Utiliza os.listdir() para obtener la lista de archivos locales\n",
    "files = os.listdir(path_carpeta_reviews)\n",
    "\n",
    "array_restaurantes = []\n",
    "array_reviews = []\n",
    "\n",
    "\n",
    "df_metadata = pd.read_csv('data-cruda/data-preprocesada/metadata_1.csv')\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith('.parquet'):\n",
    "        # Crea el path completo al archivo local\n",
    "        path_archivo = os.path.join(path_carpeta_reviews, file)\n",
    "\n",
    "        reviews = pd.read_parquet(path_archivo)\n",
    "        reviews.drop(columns=['name', 'user_id', 'pics', 'resp', 'text'], inplace=True)\n",
    "\n",
    "        restaurantes = [restaurante for restaurante in df_metadata['gmap_id']]\n",
    "\n",
    "        reviews = reviews[reviews['gmap_id'].isin(restaurantes)]\n",
    "\n",
    "        reviews.rename(columns={'time': 'fecha',\n",
    "                'rating': 'valoracion',\n",
    "                'state': 'id_estado'}, inplace=True)\n",
    "\n",
    "        reviews.drop_duplicates(inplace=True)\n",
    "        cant_reviews = reviews.value_counts(subset='gmap_id')\n",
    "        cant_reviews = pd.DataFrame(cant_reviews).reset_index()\n",
    "\n",
    "        estado = reviews['id_estado'].reset_index(drop=True)[0]\n",
    "\n",
    "        df_restaurante = pd.merge(cant_reviews, df_metadata, on='gmap_id', how='right')\n",
    "        df_restaurante = df_restaurante[df_restaurante['id_estado'] == estado]\n",
    "        array_restaurantes.append(df_restaurante)\n",
    "\n",
    "        reviews.drop(columns=['id_estado'], inplace=True)\n",
    "        array_reviews.append(reviews)\n",
    "\n",
    "\n",
    "# Final dataframe de Reviews\n",
    "\n",
    "reviews_final = pd.concat(array_reviews, ignore_index=True)\n",
    "reviews_final.to_csv('data-procesada/google-maps/reviews_google.csv')\n",
    "\n",
    "restaurantes_final = pd.concat(array_restaurantes, ignore_index=True)\n",
    "restaurantes_final.fillna(0, inplace=True)\n",
    "restaurantes_final.rename(columns={'count': 'cant_reviews', 'avg_rating': 'valoracion_promedio' }, inplace=True)\n",
    "restaurantes_final['cant_reviews'] = restaurantes_final['cant_reviews'].apply(lambda x: int(x))\n",
    "restaurantes_final = restaurantes_final[['gmap_id', 'nombre_restaurant', 'id_estado', 'cant_reviews', 'valoracion_promedio']]\n",
    "\n",
    "restaurantes_final = pd.read_csv('archivos_adicionales/google-maps_restaurantes_google.csv')\n",
    "restaurantes_final.rename(columns={'estado': 'id_estado'}, inplace=True)\n",
    "\n",
    "restaurantes_final.to_csv('data-cruda/data-preprocesada/metadata_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celda 4\n",
    "\n",
    "En esta celda, se comienzan a calcular los primeros KPIs y se agregan las columnas a la tabla de estados. La única diferencia con respecto a la función original son las rutas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurantes = pd.read_csv('data-cruda/data-preprocesada/metadata_2.csv')\n",
    "df_estados = pd.read_csv('data-cruda/data-preprocesada/estados_1.csv')\n",
    "\n",
    "## Cantidad de Restaurantes\n",
    "def calcular_cant_rest(estado):\n",
    "    return  df_restaurantes[df_restaurantes['id_estado'] == estado]['gmap_id'].count()\n",
    "\n",
    "df_estados['cant_rest'] = df_estados['id_estado'].apply(calcular_cant_rest)\n",
    "\n",
    "# Calculo de columna de CRE (Concentracion de Restaurantes por Estado)\n",
    "df_estados['CRE'] = df_estados['cant_rest'] / (df_estados['superficie_km2'] / 1000)\n",
    "\n",
    "# Calculo de columna de DCP (Densidad de consumo segun poblacion)\n",
    "df_estados['DCP'] = (df_estados['poblacion'] / 1000) / df_estados['cant_rest']\n",
    "\n",
    "df_estados.to_csv('data-cruda/data-preprocesada/estados_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celda 5\n",
    "\n",
    "<em>A partir de esta celda se vuelve monótono que el único cambio con respecto a la función original sea el cambio de rutas, por lo que no será mencionado en adelante.</em>\n",
    "\n",
    "En este caso se trabajará sobre la tabla de <em>restaurantes</em>. A cada uno se le asignará un segmento basado en la cantidad de reseñas que recibió, siendo 1 el segmento de restaurantes más pequeños y 3 el de restaurantes más grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gen_Estadisticos(data):\n",
    "    q1 = np.percentile(data, 25)\n",
    "    Mediana = np.percentile(data, 50)\n",
    "    q3 = np.percentile(data, 75)\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    minimo = min(data)\n",
    "    maximo = max(data)\n",
    "    return q1,Mediana,q3,mean,std,minimo,maximo\n",
    "\n",
    "data_umbrales = {'NC': {'mediana': 0,\n",
    "                    'reduccion': 0,\n",
    "                    'porc_reduccion': 94},\n",
    "                'SC': {'mediana': 0,\n",
    "                    'reduccion': 0,\n",
    "                    'porc_reduccion': 91},\n",
    "                'FL': {'mediana': 0,\n",
    "                    'reduccion': 0,\n",
    "                    'porc_reduccion': 91},\n",
    "                'GA': {'mediana': 0,\n",
    "                    'reduccion': 0,\n",
    "                    'porc_reduccion': 93},\n",
    "                'MD': {'mediana': 0,\n",
    "                    'reduccion': 0,\n",
    "                    'porc_reduccion': 86},\n",
    "                'VA': {'mediana': 0,\n",
    "                    'reduccion': 0,\n",
    "                    'porc_reduccion': 94}}\n",
    "\n",
    "df_estados = pd.read_csv('data-cruda/data-preprocesada/estados_2.csv')\n",
    "df_restaurantes = pd.read_csv('data-cruda/data-preprocesada/metadata_2.csv')\n",
    "\n",
    "for estado in df_estados['id_estado']:\n",
    "    \n",
    "    mask = df_restaurantes['id_estado'] == estado\n",
    "    df_temp = df_restaurantes[mask]\n",
    "\n",
    "    var = data_umbrales[estado]['porc_reduccion']\n",
    "    reduccion = np.percentile(df_temp['cant_reviews'], var)\n",
    "    \n",
    "    df_reducido = df_temp[df_temp['cant_reviews'] <= reduccion]\n",
    "    df_reducido = df_reducido[df_reducido['cant_reviews'] > 0]\n",
    "    \n",
    "    q1,mediana,q3,mean,std,minimo,maximo = Gen_Estadisticos(df_reducido.cant_reviews)\n",
    "    \n",
    "    data_umbrales[estado]['mediana'] = mediana\n",
    "    data_umbrales[estado]['reduccion'] = reduccion\n",
    "\n",
    "def Seg_comercios(valor,Partidor1,Partidor2):\n",
    "    if valor <= Partidor1:\n",
    "        var = 1\n",
    "    elif valor <= Partidor2:\n",
    "        var = 2\n",
    "    else: \n",
    "        var = 3\n",
    "    return var\n",
    "\n",
    "def apply_transform(row, umbrales):\n",
    "    estado = row['id_estado']\n",
    "    cant_reviews = row['cant_reviews']\n",
    "    for estado_umbral in umbrales:\n",
    "        if estado_umbral == estado:\n",
    "            reduccion = umbrales[estado_umbral]['reduccion']\n",
    "            mediana = umbrales[estado_umbral]['mediana']\n",
    "            return Seg_comercios(cant_reviews, mediana, reduccion)\n",
    "    return cant_reviews\n",
    "\n",
    "df_restaurantes['SEG_DCP'] = df_restaurantes.apply(lambda x: apply_transform(x, data_umbrales), axis=1)\n",
    "\n",
    "df_restaurantes.to_csv('data-cruda/data-preprocesada/metadata_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celda 6\n",
    "\n",
    "Se calculan los promedios y máximos de <strong>DCP</strong> (Densidad de Consumo Potencial) y <strong>Cantidad de reviews</strong> por estado y por segmento dentro de cada estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estados = pd.read_csv('data-cruda/data-preprocesada/estados_2.csv')\n",
    "df_restaurantes = pd.read_csv('data-cruda/data-preprocesada/metadata_3.csv')\n",
    "\n",
    "# Calculo de las columnas de promedio y maximo de reviews por estado\n",
    "def asig_Rev_Prom(estado, df):\n",
    "    return df[df[\"id_estado\"] == estado][\"cant_reviews\"].mean()\n",
    "\n",
    "def asig_Rev_Max(estado, df):\n",
    "    return df[df[\"id_estado\"] == estado][\"cant_reviews\"].max()\n",
    "\n",
    "df_estados[\"Rev_Prom\"] = df_estados[\"id_estado\"].apply(lambda x: asig_Rev_Prom(x, df_restaurantes) if True else x)\n",
    "df_estados[\"Rev_Max\"] = df_estados[\"id_estado\"].apply(lambda x: asig_Rev_Max(x, df_restaurantes) if True else x)\n",
    "\n",
    "df_estados[\"Ind_DCP_Prom\"] = df_estados[\"Rev_Prom\"] / df_estados[\"DCP\"] \n",
    "df_estados[\"Ind_DCP_Max\"] = df_estados[\"Rev_Max\"] / df_estados[\"DCP\"] \n",
    "\n",
    "# Calculo de maximo y promedio de reseñas por segmento y estado\n",
    "\n",
    "def calcular_estadisticos_segmento(data, segmento):\n",
    "    # Filtrar el DataFrame por el segmento dado\n",
    "    data_segmento = data[data[\"SEG_DCP\"] == segmento]\n",
    "\n",
    "    # Calcular el valor máximo y el promedio de reseñas por estado\n",
    "    resultados = data_segmento.groupby([\"id_estado\"])[\"cant_reviews\"].agg([\"mean\", \"max\"]).reset_index()\n",
    "    resultados.columns = [\"id_estado\", f\"Ind_DCP_prom_seg_{segmento}\", f\"Ind_DCP_max_seg_{segmento}\"]\n",
    "\n",
    "    return resultados\n",
    "\n",
    "estadisticos_seg_1 = calcular_estadisticos_segmento(df_restaurantes, 1)\n",
    "estadisticos_seg_2 = calcular_estadisticos_segmento(df_restaurantes, 2)\n",
    "estadisticos_seg_3 = calcular_estadisticos_segmento(df_restaurantes, 3)\n",
    "\n",
    "\n",
    "dataframe_estadisticas_segmentos = pd.merge(estadisticos_seg_1, estadisticos_seg_2, on='id_estado')\n",
    "dataframe_estadisticas_segmentos = pd.merge(dataframe_estadisticas_segmentos, estadisticos_seg_3, on='id_estado')\n",
    "df_estados = pd.merge(df_estados, dataframe_estadisticas_segmentos, on='id_estado')\n",
    "\n",
    "\n",
    "# Reduccion de las ultimas columnas agregadas por DCP para volverlas indices.\n",
    "columnas = [\"Ind_DCP_prom_seg_1\", \"Ind_DCP_max_seg_1\", \"Ind_DCP_prom_seg_2\", \"Ind_DCP_max_seg_2\", \"Ind_DCP_prom_seg_3\", \"Ind_DCP_max_seg_3\"]\n",
    "\n",
    "for columna in columnas:\n",
    "    df_estados[columna] = df_estados[columna] / df_estados[\"DCP\"]\n",
    "\n",
    "df_estados.to_csv('data-cruda/data-preprocesada/estados_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celda 7\n",
    "\n",
    "Se calculan, de igual manera que en la celda anterior, los valores medios y máximos de <strong>PEE</strong> (índice de percepción) tanto por estado como por segmento por estado. Se basa en la valoración promedio de cada establecimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estados = pd.read_csv('data-cruda/data-preprocesada/estados_3.csv')\n",
    "df_restaurantes = pd.read_csv('data-cruda/data-preprocesada/metadata_3.csv')\n",
    "\n",
    "# Calculo de las columnas de PEE_prom y PEE_max\n",
    "\n",
    "promedio_valoracion_por_estado = df_restaurantes.groupby(\"id_estado\")[\"valoracion_promedio\"].mean().reset_index()\n",
    "maximo_valoracion_por_estado = df_restaurantes.groupby('id_estado')['valoracion_promedio'].max().reset_index()\n",
    "\n",
    "# Renombrar la columna resultante\n",
    "promedio_valoracion_por_estado.columns = [\"id_estado\", \"PEE_prom\"]\n",
    "maximo_valoracion_por_estado.columns = ['id_estado', 'PEE_max']\n",
    "\n",
    "dataframe_pee_max_prom = pd.merge(promedio_valoracion_por_estado, maximo_valoracion_por_estado, on='id_estado')\n",
    "dataframe_pee_max_prom\n",
    "\n",
    "df_estados = pd.merge(df_estados, dataframe_pee_max_prom, on='id_estado')\n",
    "\n",
    "#Calculo de las columnas de PEE_prom y PEE_max por estado\n",
    "\n",
    "# Calcular el promedio de \"valoracion_promedio\" por estado y segmento\n",
    "promedio_valoracion_por_estado_segmento = df_restaurantes.groupby([\"id_estado\", \"SEG_DCP\"])[\"valoracion_promedio\"].mean().reset_index()\n",
    "\n",
    "# Calcular el máximo de \"valoracion_promedio\" por estado y segmento\n",
    "maximo_valoracion_por_estado_segmento = df_restaurantes.groupby([\"id_estado\", \"SEG_DCP\"])[\"valoracion_promedio\"].max().reset_index()\n",
    "\n",
    "# Renombrar las columnas resultantes\n",
    "promedio_valoracion_por_estado_segmento.columns = [\"id_estado\", \"SEG_DCP\", \"PEE_prom\"]\n",
    "maximo_valoracion_por_estado_segmento.columns = [\"id_estado\", \"SEG_DCP\", \"PEE_max\"]\n",
    "\n",
    "# Pivotear los DataFrames para obtener el formato deseado\n",
    "promedio_valoracion_por_estado_segmento = promedio_valoracion_por_estado_segmento.pivot(index=\"id_estado\", columns=\"SEG_DCP\", values=\"PEE_prom\").reset_index()\n",
    "maximo_valoracion_por_estado_segmento = maximo_valoracion_por_estado_segmento.pivot(index=\"id_estado\", columns=\"SEG_DCP\", values=\"PEE_max\").reset_index()\n",
    "\n",
    "# Renombrar las columnas de los DataFrames pivotados\n",
    "promedio_valoracion_por_estado_segmento.columns = [\"id_estado\", \"PEE_prom_seg_1\", \"PEE_prom_seg_2\", \"PEE_prom_seg_3\"]\n",
    "maximo_valoracion_por_estado_segmento.columns = [\"id_estado\", \"PEE_max_seg_1\", \"PEE_max_seg_2\", \"PEE_max_seg_3\"]\n",
    "\n",
    "# Combinar los resultados en un solo DataFrame\n",
    "resultados_pee = pd.merge(promedio_valoracion_por_estado_segmento, maximo_valoracion_por_estado_segmento, on=\"id_estado\")\n",
    "\n",
    "df_estados = pd.merge(df_estados, resultados_pee, on='id_estado')\n",
    "\n",
    "df_estados.to_csv('data-cruda/data-preprocesada/estados_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celda 8\n",
    "\n",
    "Con respecto a la tabla de estados, se normalizan algunos índices calculados previamente para que puedan ser comparados entre sí. Por otro lado, a la tabla de restaurantes se le agregan columnas que indican presencia o ausencia de la condición de estar por encima del promedio de PEE y DCP de su estado, es decir, un 1 corresponde a estar por encima del promedio, mientras que un 0 indica que no se está.\n",
    "\n",
    "Aquí concluyen las transformaciones a las tablas y los datos ya pueden ser consumidos por el equipo de análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estados = pd.read_csv('data-cruda/data-preprocesada/estados_4.csv')\n",
    "df_restaurantes = pd.read_csv('data-cruda/data-preprocesada/metadata_3.csv')\n",
    "# Normalizacion\n",
    "\n",
    "def normalizacion(valor,minimo,maximo,base,min_base):\n",
    "    var = min_base + (((valor - minimo) / (maximo - minimo)) * base)\n",
    "    return var\n",
    "\n",
    "lista_indices = [\"Ind_DCP_prom_seg_1\",\"Ind_DCP_prom_seg_2\",\"Ind_DCP_prom_seg_3\",\"Ind_DCP_max_seg_1\",\"Ind_DCP_max_seg_2\",\"Ind_DCP_max_seg_3\"]\n",
    "lista_ind_Nor = [\"Ind_DCP_prom_seg_1_nor\",\"Ind_DCP_prom_seg_2_nor\",\"Ind_DCP_prom_seg_3_nor\",\"Ind_DCP_max_seg_1_nor\",\"Ind_DCP_max_seg_2_nor\",\"Ind_DCP_max_seg_3_nor\"]\n",
    "for i in range(0,len(lista_indices)):\n",
    "    minimo = df_estados[lista_indices[i]].min()\n",
    "    maximo = df_estados[lista_indices[i]].max()\n",
    "    df_estados[lista_ind_Nor[i]] = df_estados[lista_indices[i]].apply(lambda x:normalizacion(x,minimo,maximo,80,20) if True else x)\n",
    "\n",
    "\n",
    "df_estados = df_estados[[\"id_estado\",\"estado\",\"superficie_km2\",\"poblacion\",\"cant_rest\",\n",
    "                        \"CRE\",\"DCP\",\"Rev_Prom\",\"Rev_Max\",\"PEE_prom\",\"PEE_max\",\n",
    "                        \"Ind_DCP_Prom\",\"Ind_DCP_Max\",\n",
    "                        \"Ind_DCP_prom_seg_1\",\"Ind_DCP_prom_seg_1_nor\",\n",
    "                        \"Ind_DCP_prom_seg_2\",\"Ind_DCP_prom_seg_2_nor\",\n",
    "                        \"Ind_DCP_prom_seg_3\",\"Ind_DCP_prom_seg_3_nor\",\n",
    "                        \"Ind_DCP_max_seg_1\",\"Ind_DCP_max_seg_1_nor\",\n",
    "                        \"Ind_DCP_max_seg_2\",\"Ind_DCP_max_seg_2_nor\",\n",
    "                        \"Ind_DCP_max_seg_3\",\"Ind_DCP_max_seg_3_nor\",\n",
    "                        \"PEE_prom_seg_1\",\"PEE_prom_seg_2\",\"PEE_prom_seg_3\",\n",
    "                        \"PEE_max_seg_1\",\"PEE_max_seg_2\",\"PEE_max_seg_3\"]]\n",
    "\n",
    "\n",
    "\n",
    "def calcular_cumple(row):\n",
    "    estado = row[\"id_estado\"]\n",
    "    segmento = row[\"SEG_DCP\"]\n",
    "    cant_reviews = row[\"cant_reviews\"]\n",
    "    valoracion_promedio = row[\"valoracion_promedio\"]\n",
    "    rest_id = row['gmap_id']\n",
    "\n",
    "    # Obtener los valores de DCP_prom y PEE_prom correspondientes al estado y segmento\n",
    "    DCP_prom = df_estados[(df_estados[\"id_estado\"] == estado)][f\"Ind_DCP_prom_seg_{segmento}\"].values[0]\n",
    "    PEE_prom = df_estados[(df_estados[\"id_estado\"] == estado)][f\"PEE_prom_seg_{segmento}\"].values[0]\n",
    "\n",
    "    # Calcular las condiciones y asignar 1 o 0\n",
    "    DCP_cumple = 1 if cant_reviews > DCP_prom else 0\n",
    "    PEE_cumple = 1 if valoracion_promedio > PEE_prom else 0\n",
    "\n",
    "    return pd.Series({'gmap_id': rest_id, \"DCP_cumple\": DCP_cumple, \"PEE_cumple\": PEE_cumple})\n",
    "\n",
    "\n",
    "df_restaurantes = pd.merge(df_restaurantes, df_restaurantes.apply(calcular_cumple, axis=1), on='gmap_id')\n",
    "\n",
    "df_estados.to_csv('data-procesada/google-maps/estados.csv', index=False)\n",
    "df_restaurantes.to_csv('data-procesada/google-maps/restaurantes.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
